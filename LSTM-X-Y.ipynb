{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy \n",
    "import pandas as pd\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pylab import *\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from scipy. ndimage import filters\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Model, Sequential, save_model, load_model\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import h5py\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def preprocess(data_dirs, data_file,name):\n",
    "    # all_ped_data would be a dictionary with mapping from each ped to their\n",
    "    # trajectories given by matrix 3 x numPoints with each column\n",
    "    # in the order x, y, frameId\n",
    "    # Pedestrians from all datasets are combined\n",
    "    # Dataset pedestrian indices are stored in dataset_indices\n",
    "    all_ped_data={}\n",
    "    dataset_indices=[]\n",
    "    current_ped = 0\n",
    "    # For each dataset\n",
    "    for directory in data_dirs:\n",
    "        # Define the path to its respective csv file\n",
    "        #PETS2009-S2L1-mmundo.csv\n",
    "        #'PETS09-S2L1.txt'\n",
    "        file_path = os.path.join(directory,name )\n",
    "\n",
    "        # Cargar datos desde el archivo csv\n",
    "        # Los datos son una matriz 4x numTrajPoints\n",
    "        \n",
    "        \n",
    "        data = np.genfromtxt(file_path, delimiter=',')\n",
    "       \n",
    "        \n",
    "        # Obtenga el numero de peatones en el conjunto de datos actual\n",
    "        uni=np.unique(data[:,1])    \n",
    "        numPeds=np.size(np.unique(data[:,1]))\n",
    "        \n",
    "        print(\"peatones.............\")\n",
    "        print(numPeds)\n",
    "       \n",
    "        # Para cada peaton en el conjunto de datos\n",
    "        for ped in range(1, numPeds+1):\n",
    "            #Son los datos de la persona ped\n",
    "            traj = data[ data[:, 1] == ped]\n",
    "            #Esta como (x,y,frame_Id)\n",
    "            traj = traj[:, [2,3,0]]\n",
    "            \n",
    "            #Esta como [[x,...],[y,...],[Frame_Id,..]]\n",
    "            traj=[list(traj[:,0]),list(traj[:,1]),list(traj[:,2])]\n",
    "            all_ped_data[current_ped + ped] = np.array(traj)\n",
    "\n",
    "        # Current dataset done\n",
    "        dataset_indices.append(current_ped+numPeds)\n",
    "        current_ped += numPeds\n",
    "\n",
    "    # Los datos completos son una tupla de todos los datos de peatones y los indices de datos del conjunto de datos.\n",
    "    complete_data = (all_ped_data, dataset_indices)\n",
    "    # Almacena los datos completos en el archivo pickle\n",
    "    f = open(data_file, \"wb\")\n",
    "    pickle.dump(complete_data, f, protocol=2)\n",
    "    f.close()\n",
    "    return complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed(data_file,seq_length_obs,batch_size):\n",
    "    \n",
    "    # cargar los datos\n",
    "    f = open(data_file, \"rb\")\n",
    "    raw_data = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Obtengo los peatones\n",
    "    all_ped_data =raw_data[0]\n",
    " \n",
    "    #all_ped_data es el vector {[[],[],[]],...,[[],[],[]]} tantos como pedestrian hayan\n",
    "    # No usamos dataset_indices por ahora\n",
    "    # dataset_indices = self.raw_data[1]\n",
    "\n",
    "    # Construimos data con secuencias(o trayectorias) del largo than seq_length_obs\n",
    "    data = []\n",
    "    counter = 0\n",
    "\n",
    "    # para cada peaton en data\n",
    "    for ped in all_ped_data:\n",
    "        \n",
    "        #ped es un numero entero y va de 1 hasta la cantidad total de pedestrian\n",
    "        # Extract his trajectory\n",
    "        traj = all_ped_data[ped]\n",
    "           \n",
    "        #print(traj.shape)\n",
    "        # If the length of the trajectory is greater than seq_length (+2 as we need both source and target data)\n",
    "        #solo se toman las trajectorias de longitud mayor a seq_length+2\n",
    "        if traj.shape[1] >= (seq_length_obs+1):\n",
    "            # TODO: (Improve) Store only the (x,y) coordinates for now\n",
    "            \n",
    "            #print(traj[[0, 1], :].shape)\n",
    "            data.append(traj[[0, 1], :].T)\n",
    "            #print(traj[[0, 1], :].T)\n",
    "            # Number of batches this datapoint is worth\n",
    "            #print(traj.shape[1] )\n",
    "            #print(int(traj.shape[1] / ((seq_length_obs+1))))\n",
    "            counter += int(traj.shape[1] / ((seq_length_obs+1)))\n",
    "        \n",
    "    # Calculate the number of batches (each of batch_size) in the data\n",
    "    #counter tiene la cantidad de bloques de 8 pasos\n",
    "        \n",
    "    num_batches = int(counter /batch_size)\n",
    "    #cada bache tiene batch_size conjuntos donde cada conjunto tiene datos de length+2\n",
    "    return data,num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peatones.............\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dirs = ['../data1/pets']\n",
    "datasets=[0]\n",
    "#data_dirs=['../data1/ucy/univ','../data1/ucy/zara/zara02','../data1/eth/hotel','../data1/ucy/zara/zara01']\n",
    "\n",
    "#prueba=['../data1/eth/univ']\n",
    "#datasets=[0,1,2,3]\n",
    "used_data_dirs = [data_dirs[x] for x in datasets]\n",
    "#Directorio de datos donde reside el archivo pickle preprocesado\n",
    "data_dir = '../data1'\n",
    "\n",
    "#Defina la ruta del archivo en el que deben almacenarse los datos.\n",
    "data_file = os.path.join(data_dir, \"datos_limpios_.cpkl\")\n",
    "\n",
    "name ='pixel_pos.csv'\n",
    "# If the file doesn't exist already or if forcePreProcess is true\n",
    "#se usa preprocesscsv para los csv y preprocess para el .txt\n",
    "\n",
    "#print(used_data_dirs)\n",
    "data = preprocess(used_data_dirs, data_file,name)\n",
    "datos,numero = load_preprocessed(data_file,12,1)#los ultimos dos valores noimportan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datos[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datos[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secuencia(seq_length_obs,data):  \n",
    "    tamano=int(len(data))\n",
    "    \n",
    "    X,Y=[],[]\n",
    "    for j in range(tamano):\n",
    "        traj = data[j]\n",
    "        lon = traj.shape[0]-seq_length_obs\n",
    "    #lon=data.shape[0]-seq_length_obs-seq_length_pred\n",
    "        for i in range(0,lon):\n",
    "            a = traj[i:(i +seq_length_obs ), :]\n",
    "            X.append(a)\n",
    "            b = traj[i +seq_length_obs,:]\n",
    "            Y.append(b)\n",
    "    return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "import random\n",
    "color_names = [\"r\",\"crimson\" ,\"g\", \"b\",\"c\",\"m\",\"y\",\"lightcoral\", \"peachpuff\",\"grey\",\"springgreen\" ,\"fuchsia\",\"violet\",\"teal\",\"seagreen\",\"lime\",\"yellow\",\"coral\",\"aquamarine\",\"hotpink\"]\n",
    "\n",
    "for i in range(len(datos)):\n",
    "    cpu = random.choice(range(17))\n",
    "    pintar = plt.plot(datos[i][:,0],datos[i][:,1],color=color_names[i])\n",
    "plt.title(\" Trayectorias completas de PETS-2009\") \n",
    "plt.xlabel(\"Coordenada x\")   \n",
    "plt.ylabel(\"Coordenada y\") \n",
    "\n",
    "#plt.savefig(\"trayectorias.jpg\")\n",
    "plt.show() \n",
    "\"\"\"\n",
    "\n",
    "print(len(datos[3][:,0]))\n",
    "print(len(datos[4][:,0]))\n",
    "\n",
    "for i in range(4,7):\n",
    "    cpu = random.choice(range(17))\n",
    "    if(i==4):\n",
    "        pintar = plt.plot(datos[i][165:180,0],datos[i][165:180,1],color=color_names[cpu])\n",
    "    if(i==6): \n",
    "        #print(len(datos[6][:,1]))\n",
    "        pintar = plt.plot(datos[i][15:30,0],datos[i][15:30,1],color=color_names[cpu])\n",
    "        \n",
    "plt.title(\" Trayectorias completas de PETS-2009\") \n",
    "plt.xlabel(\"Coordenada x\")   \n",
    "plt.ylabel(\"Coordenada y\") \n",
    "\n",
    "#plt.savefig(\"trayectorias.jpg\")\n",
    "plt.show() \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como se divide los conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitud=len(datos)\n",
    "ind = range(longitud)\n",
    "\n",
    "lista = []\n",
    "for i in range(0,longitud,4):\n",
    "    lista.append(ind[i:i+4])\n",
    "print(lista)\n",
    "\n",
    "combinacion=[(0,1,2,3,4),(0,1,2,4,3),(0,1,3,4,2),(0,2,3,4,1),(1,2,3,4,0)]\n",
    "\n",
    "def conjunto_datos(combinacion,lista,datos):\n",
    "    conjunto_entrenamiento = []\n",
    "    for i in range(len(combinacion)-1):\n",
    "       # print(i)\n",
    "        for j in lista[combinacion[i]]:\n",
    "        #    print(j)\n",
    "            conjunto_entrenamiento.append(datos[j])\n",
    "    conjunto_prueba=[]\n",
    "    for i in lista[combinacion[4]]:\n",
    "        #print(shape(datos[i]))\n",
    "        conjunto_prueba.append(datos[i])\n",
    "    \n",
    "    return conjunto_entrenamiento,conjunto_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1,test1 = conjunto_datos(combinacion[0],lista,datos)\n",
    "#vali1=[test1[0]]\n",
    "train2,test2 = conjunto_datos(combinacion[1],lista,datos)\n",
    "#vali2=[test2[0]]\n",
    "train3,test3 = conjunto_datos(combinacion[2],lista,datos)\n",
    "train4,test4 = conjunto_datos(combinacion[3],lista,datos)\n",
    "train5,test5 = conjunto_datos(combinacion[4],lista,datos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_obs = 8\n",
    "trainX,trainY = secuencia(length_obs,train5)\n",
    "#valiX,valiY = secuencia(length_obs,vali2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1],trainX.shape[2]))\n",
    "#valiX= numpy.reshape(valiX, (valiX.shape[0], valiX.shape[1],valiX.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = trainX.shape[1:]\n",
    "print(data_shape)\n",
    "import numpy as np\n",
    "np.shape(trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para entrenar varios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_obs = 8\n",
    "trainX,trainY = secuencia(length_obs,datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1],trainX.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = trainX.shape[1:]\n",
    "print(data_shape)\n",
    "import numpy as np\n",
    "np.shape(trainX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseño de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "#from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "#from keras.layers import GRU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import initializers\n",
    "from datetime import datetime\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "if 'model' in globals(): del model\n",
    "model = None\n",
    "model = Sequential()\n",
    "model.add(LSTM(9, return_sequences=True, input_shape=data_shape, name='lstm1'))\n",
    "model.add(LSTM(9, name='lstm2'))\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_data=(vali_obs, vali_pred),\n",
    "opt = optimizers.RMSprop(lr = 0.006, decay=1e-2)\n",
    "model.compile(optimizer=opt, loss='logcosh',metrics=['mse'])\n",
    "history= model.fit(trainX, trainY, epochs=100, batch_size=16, verbose=2)\n",
    "#plot_model(model, show_shapes=True, to_file='modelo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict= history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['mean_squared_error']\n",
    "#val_acc = history.history['val_mean_squared_error']\n",
    "loss = history.history['loss']\n",
    "#val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "# figure\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "#plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, acc, 'r', label='Training mse')\n",
    "#plt.plot(epochs, val_acc, 'g', label='Validation mse')\n",
    "plt.title('Training mse')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy1-simplicado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy2-simplicado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy3-simplicado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy5-simplicado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy-ucy-univ.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy-eth-hotel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy-ucy-zara-zara01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy-ucy-zara-zara02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('lstm-xy-eth-univ.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelxy = load_model('lstm-xy5-simplicado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs=['../data1/ucy/univ']\n",
    "datasets=[0]\n",
    "\n",
    "used_data_dirs = [data_dirs[x] for x in datasets]\n",
    "#Directorio de datos donde reside el archivo pickle preprocesado\n",
    "data_dir = '../data1'\n",
    "\n",
    "#Defina la ruta del archivo en el que deben almacenarse los datos.\n",
    "data_file = os.path.join(data_dir, \"datos_limpios_prueba.cpkl\")\n",
    "\n",
    "name ='pixel_pos.csv'\n",
    "# If the file doesn't exist already or if forcePreProcess is true\n",
    "#se usa preprocesscsv para los csv y preprocess para el .txt\n",
    "\n",
    "#print(used_data_dirs)\n",
    "data1 = preprocess(used_data_dirs, data_file,name)\n",
    "datos_prueb,numero = load_preprocessed(data_file,12,1)#los ultimos dos valores noimportan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores para medir las trayectorias predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_promedio(predicted_traj, true_traj, observed_length):\n",
    "    \n",
    "    error = np.zeros(len(true_traj) - observed_length)\n",
    "    # PARA CADA PUNTO EN LA TRAYECTORIA PREDICHA\n",
    "    for i in range(observed_length, len(true_traj)):\n",
    "        # The predicted position\n",
    "        pred_pos = predicted_traj[i]\n",
    "        # The true position\n",
    "        true_pos = true_traj[i]\n",
    "\n",
    "        # The euclidean distance is the error\n",
    "        error[i-observed_length] = np.linalg.norm(true_pos - pred_pos)\n",
    "\n",
    "    # Return the mean error\n",
    "    return np.mean(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_desplazamiento_final(predicted_traj, true_traj):\n",
    "    tam = len(predicted_traj)\n",
    "    return np.linalg.norm(predicted_traj[tam-1]-true_traj[tam-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta funcion construye secuencias con solo la parte observada y secuencias completa\n",
    "# es decir secuencia de longitud obs+pred\n",
    "\n",
    "def secuencia_pred(seq_length_obs,data,seq_length_pred):\n",
    "    \n",
    "    tamano = int(len(data))\n",
    "    X,Y_true = [],[]\n",
    "    # se recorre todo los datos de test\n",
    "    for j in range(tamano):\n",
    "        traj = data[j]\n",
    "        \n",
    "        lon = traj.shape[0]-seq_length_obs-seq_length_pred\n",
    "        #lon=data.shape[0]-seq_length_obs-seq_length_pred\n",
    "        for i in range(0,lon+1):\n",
    "            a = traj[i:(i +seq_length_obs ), :]\n",
    "            \n",
    "            X.append(a)\n",
    "            # esta parte tiene tanto la parte observada como \n",
    "            b = traj[i: (i+seq_length_obs+seq_length_pred), :]\n",
    "        \n",
    "            Y_true.append(b)\n",
    "    return np.array(X),np.array(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion predice posiciones pred normalizados\n",
    "\n",
    "def sample(datos, seq_length_obs, seq_length_pred):\n",
    "    \n",
    "    X,Y_true = secuencia_pred(seq_length_obs,datos,seq_length_pred)\n",
    "    total_error = 0.0\n",
    "    total_final = 0.0\n",
    "    todo=[]\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        traj_obs = X[i]\n",
    "        traj_pred = X[i]\n",
    "    \n",
    "        #print(Y_true[i])\n",
    "        \n",
    "        for j in range(seq_length_pred):\n",
    "            traj_obsr = numpy.reshape(traj_obs, (1,traj_obs.shape[0],traj_obs.shape[1]) )\n",
    "            #print(traj_obsr)\n",
    "            predict = modelxy.predict(traj_obsr)\n",
    "            next_point = predict\n",
    "            traj_obs = np.concatenate((traj_obs[1:len(traj_obs)],next_point),axis=0)\n",
    "            traj_pred = np.concatenate((traj_pred,next_point),axis=0)\n",
    "            \n",
    "        diff=Y_true[i][seq_length_obs:]-traj_pred[seq_length_obs:]\n",
    "        diff=diff**2\n",
    "        diff=np.sqrt(np.sum(diff,axis=1))\n",
    "        todo.append(diff)\n",
    "    \n",
    "        total_error +=  error_promedio(traj_pred , Y_true[i], seq_length_obs)\n",
    "        total_final += error_desplazamiento_final(traj_pred, Y_true[i])\n",
    "        \n",
    "        \n",
    "    #print(todo)\n",
    "    error_ade_modelo = total_error/len(X)\n",
    "    error_fde_modelo = total_final/len(X)\n",
    "    \n",
    "    ade=[t for o in todo for t in o]\n",
    "    \n",
    "    print('---------Error--------')\n",
    "    print('ADE')\n",
    "    print(np.mean(ade))\n",
    "\n",
    "    print(error_ade_modelo)\n",
    "    print('FDE')\n",
    "    print(error_fde_modelo)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion hace la prediccion en coordenadas pixel\n",
    "def sample_en_pixeles(datos, seq_length_obs, seq_length_pred):\n",
    "    \n",
    "    X,Y_true = secuencia_pred(seq_length_obs,datos,seq_length_pred)\n",
    "    total_error = 0.0\n",
    "    total_final = 0.0\n",
    "    todo = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        traj_obs = X[i]\n",
    "        traj_pred = X[i]\n",
    "    \n",
    "        #print(Y_true[i])\n",
    "        \n",
    "        for j in range(seq_length_pred):\n",
    "            traj_obsr = numpy.reshape(traj_obs, (1,traj_obs.shape[0],traj_obs.shape[1]) )\n",
    "            #print(traj_obsr)\n",
    "            predict = modelxy.predict(traj_obsr)\n",
    "            next_point = predict\n",
    "            traj_obs = np.concatenate((traj_obs[1:len(traj_obs)],next_point),axis=0)\n",
    "            traj_pred = np.concatenate((traj_pred,next_point),axis=0)\n",
    "        \n",
    "        traj_pre =  np.column_stack((768*traj_pred[:,0],576*traj_pred[:,1]))\n",
    "        traj_tr = np.column_stack((768*Y_true[i][:,0],576*Y_true[i][:,1]))\n",
    "          \n",
    "        diff = traj_pre[seq_length_obs:]-traj_tr[seq_length_obs:]\n",
    "        diff = diff**2\n",
    "        diff = np.sqrt(np.sum(diff,axis=1))\n",
    "        todo.append(diff)\n",
    "        \n",
    "        total_error += error_promedio(traj_pre , traj_tr, seq_length_obs)\n",
    "        total_final += error_desplazamiento_final(traj_pre, traj_tr)\n",
    "             \n",
    "    error_modelo = total_error/len(X)\n",
    "    error_fde_modelo = total_final/len(X)\n",
    "    \n",
    "    ade=[t for o in todo for t in o]\n",
    "    \n",
    "    print('---------Error--------')\n",
    "    print('ADE')\n",
    "    print(np.mean(ade))\n",
    "    \n",
    "    print('Error promedio')\n",
    "    print(error_modelo)\n",
    "    print('FDE')\n",
    "    print(error_fde_modelo)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(datos_prueb,8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_en_pixeles(test5,8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo=[0.011135076322301925,0.01779901295573725,0.010485664737981631,0.013785845624867498,0.03644201283933346]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(todo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las primeras 8 posiciones de todos los peatones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secuencia_x_persona(seq_length_obs,data,seq_length_pred):\n",
    "    tamano = int(len(data))\n",
    "    X,Y_true = [],[]\n",
    "    for j in range(tamano):\n",
    "        traj = data[j]\n",
    "        X.append(traj[0:seq_length_obs,:])\n",
    "        Y_true.append(traj[0:seq_length_obs+seq_length_pred,:])\n",
    "    return np.array(X),np.array(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_x_persona_normalizado(datos, seq_length_obs, seq_length_pred):\n",
    "    \n",
    "    X,Y_true = secuencia_x_persona(seq_length_obs,datos,seq_length_pred)\n",
    "    total_error = 0.0\n",
    "    plt.figure(figsize=(18,15)) \n",
    "    color_names = [\"r\",\"crimson\" ,\"g\", \"b\",\"c\",\"m\",\"y\",\"lightcoral\", \"peachpuff\",\"grey\",\"springgreen\" ,\"fuchsia\",\"violet\",\"teal\",\"seagreen\",\"lime\",\"yellow\",\"coral\",\"aquamarine\",\"hotpink\"]\n",
    "\n",
    "    todo = []\n",
    "    for i in range(len(X)):\n",
    "        traj_obs = X[i]\n",
    "        traj_pred = X[i]\n",
    "    \n",
    "        for j in range(seq_length_pred):\n",
    "            traj_obsr = numpy.reshape(traj_obs, (1,traj_obs.shape[0],traj_obs.shape[1]) )\n",
    "            #print(traj_obsr)\n",
    "            predict = modelxy.predict(traj_obsr)\n",
    "            next_point = predict\n",
    "          \n",
    "            traj_obs = np.concatenate((traj_obs[1:len(traj_obs)],next_point),axis=0)\n",
    "            traj_pred = np.concatenate((traj_pred,next_point),axis=0)\n",
    "        \n",
    "        diff = Y_true[i][seq_length_obs:]-traj_pred[seq_length_obs:]\n",
    "        diff = diff**2\n",
    "        diff = np.sqrt(np.sum(diff,axis=1))\n",
    "        \n",
    "        todo.append(diff)\n",
    "        error_prom = error_promedio(traj_pred ,Y_true[i], seq_length_obs)\n",
    "        FDE = error_desplazamiento_final(traj_pred , Y_true[i])\n",
    "        \n",
    "\n",
    "        print(\"TRAYECTORIA PREDICHA DEL PEATON \",i+1)\n",
    "        print(traj_pred)\n",
    "        print(\"TRAYECTORIA VERDADERA  \")\n",
    "        print(Y_true[i])\n",
    "        print(\"EL ERROR PROMEDIO DE LA TRAYECTORIA PREDICHA ES = {:.3f} \".format(error_prom))\n",
    "        print(\"ERROR DE DESPLAZAMIENTO FINAL ES ={:.3f}\".format(FDE))\n",
    "                         \n",
    "        #cpu = random.choice(range(17))\n",
    "                         \n",
    "        subplot(1,1,1)\n",
    "        \n",
    "        \n",
    "        #predicha=plt.plot(X[i][:,0],X[i][:,1],'*--',color=color_names[cpu])\n",
    "        predicha=plt.plot(Y_true[i][:,0],Y_true[i][:,1],'*--',color=color_names[19-i])\n",
    "        predicha=plt.plot(traj_pred[seq_length_obs-1:(seq_length_obs+seq_length_pred),0],\n",
    "                                  traj_pred[seq_length_obs-1:(seq_length_obs+seq_length_pred),1],'o--',color=color_names[i])\n",
    "        plt.title(\"Cuatro posiciones predichas con LTM-X-Y\") \n",
    "        plt.xlabel('Coordenada x')\n",
    "        plt.ylabel('Coordenada y')\n",
    "        \n",
    "        \n",
    "        total_error += error_prom\n",
    "    ade=[t for o in todo for t in o]\n",
    "    error_modelo = total_error/len(X)\n",
    "    print(\"EL ERROR PROMEDIO DE TODA LA PREDICCIÓN\")\n",
    "    print(error_modelo)\n",
    "    print(\"Error ade\")\n",
    "    print(np.mean(ade))\n",
    "    plt.savefig(\"4predichas.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x_persona_normalizado(datos,8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_x_persona_pixeles(datos, seq_length_obs, seq_length_pred):\n",
    "    \n",
    "    X,Y_true = secuencia_x_persona(seq_length_obs,datos,seq_length_pred)\n",
    "    total_error = 0.0\n",
    "    plt.figure(figsize=(18,15))  \n",
    "    color_names = [\"r\", \"g\", \"b\",\"c\",\"m\",\"y\", \"peachpuff\",\"grey\", \"fuchsia\",\"violet\",\n",
    "                   \"teal\",\"seagreen\",\"lime\",\"yellow\",\"coral\",\"aquamarine\",\"hotpink\"]\n",
    "    todo=[]\n",
    "    for i in range(len(X)):\n",
    "        traj_obs = X[i]\n",
    "        traj_pred = X[i]\n",
    "    \n",
    "        for j in range(seq_length_pred):\n",
    "            traj_obsr = numpy.reshape(traj_obs, (1,traj_obs.shape[0],traj_obs.shape[1]) )\n",
    "            #print(traj_obsr)\n",
    "            predict = modelxy.predict(traj_obsr)\n",
    "            next_point = predict\n",
    "          \n",
    "            traj_obs = np.concatenate((traj_obs[1:len(traj_obs)],next_point),axis=0)\n",
    "            traj_pred = np.concatenate((traj_pred,next_point),axis=0)\n",
    "    \n",
    "    ss\n",
    "        traj_pre =  np.column_stack((768*traj_pred[:,0],576*traj_pred[:,1]))\n",
    "        traj_tr = np.column_stack((768*Y_true[i][:,0],576*Y_true[i][:,1]))\n",
    "       \n",
    "        \n",
    "        diff = traj_tr[seq_length_obs:]-traj_pre[seq_length_obs:]\n",
    "        diff = diff**2\n",
    "        diff = np.sqrt(np.sum(diff,axis=1))\n",
    "        \n",
    "        todo.append(diff)\n",
    "        error_prom = error_promedio(traj_pre , traj_tr, seq_length_obs)\n",
    "        FDE = error_desplazamiento_final(traj_pre , traj_tr)\n",
    "        \n",
    "    \n",
    "\n",
    "        print(\"TRAYECTORIA PREDICHA DEL PEATON \",i+1)\n",
    "        print(traj_pre)\n",
    "        print(\"TRAYECTORIA VERDADERA  \")\n",
    "        print(traj_tr)\n",
    "        print(\"EL ERROR PROMEDIO DE LA TRAYECTORIA PREDICHA ES = {:.3f} \".format(error_prom))\n",
    "        print(\"ERROR DE DESPLAZAMIENTO FINAL ES ={:.3f}\".format(FDE))\n",
    "                         \n",
    "        cpu = random.choice(range(17))\n",
    "                         \n",
    "        subplot(1,1,1)\n",
    "        \n",
    "        predicha=plt.plot(traj_tr[:,0],traj_tr[:,1],'*--',color=color_names[cpu])                \n",
    "        predicha=plt.plot(traj_pre[seq_length_obs:(seq_length_obs+seq_length_pred),0],\n",
    "                                  traj_pre[seq_length_obs:(seq_length_obs+seq_length_pred),1],'o--',color=color_names[cpu])\n",
    "        \n",
    "        plt.title(\"Cuatro posiciones predichas con LSTM-DX-DY\") \n",
    "        plt.xlabel('Coordenada x')\n",
    "        plt.ylabel('Coordenada y')\n",
    "        \n",
    "        \n",
    "        total_error += error_prom\n",
    "    error_modelo = total_error/len(X)\n",
    "    ade=[t for o in todo for t in o]\n",
    "    print(\"EL ERROR PROMEDIO DE TODA LA PREDICCIÓN\")\n",
    "    print(error_modelo)\n",
    "    print('Error ADE')\n",
    "    print(np.mean(ade))\n",
    "    #plt.savefig(\"trayectoriasdxdy_pixel.jpg\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_x_persona_pixeles(datos,8,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trayectorias para la evaluacion cualitativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cruce = []\n",
    "cruce.append(datos[3][252:264,:])\n",
    "cruce.append(datos[4][135:147,:])\n",
    "\n",
    "paralelos = []\n",
    "paralelos.append(datos[2][1:13])\n",
    "paralelos.append(datos[3][20:32])\n",
    "\n",
    "inverso = []\n",
    "inverso.append(datos[4][167:179])\n",
    "inverso.append(datos[6][15:27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30011341, 0.40633819],\n",
       "       [0.30590104, 0.40479427],\n",
       "       [0.31172969, 0.40319566],\n",
       "       [0.3176612 , 0.40145833],\n",
       "       [0.32378333, 0.39946319],\n",
       "       [0.33016445, 0.39711771],\n",
       "       [0.3368043 , 0.39442187],\n",
       "       [0.34361732, 0.39148264],\n",
       "       [0.35047604, 0.38845035],\n",
       "       [0.35723346, 0.3854776 ],\n",
       "       [0.36374049, 0.38270017],\n",
       "       [0.36989193, 0.38021059]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cruce[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion hace la prediccion en coordenadas pixel\n",
    "def sample_en_pixeles_cualitativamente(datos, seq_length_obs, seq_length_pred):\n",
    "    \n",
    "    \n",
    "    X,Y_true = secuencia_pred(seq_length_obs,datos,seq_length_pred)\n",
    "    total_error = 0.0\n",
    "    total_final = 0.0\n",
    "    todo = []\n",
    "    trayectoria = []\n",
    "    verdadero= []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        traj_obs = X[i]\n",
    "        traj_pred = X[i]\n",
    "        \n",
    "        for j in range(seq_length_pred):\n",
    "            traj_obsr = numpy.reshape(traj_obs, (1,traj_obs.shape[0],traj_obs.shape[1]) )\n",
    "            #print(traj_obsr)\n",
    "            predict = modelxy.predict(traj_obsr)\n",
    "            next_point = predict\n",
    "            traj_obs = np.concatenate((traj_obs[1:len(traj_obs)], next_point), axis = 0)\n",
    "            traj_pred = np.concatenate((traj_pred, next_point), axis = 0)\n",
    "        \n",
    "        traj_pre =  np.column_stack((768*traj_pred[:,0],576*traj_pred[:,1]))\n",
    "        traj_tr = np.column_stack((768*Y_true[i][:,0],576*Y_true[i][:,1]))\n",
    "       \n",
    "        trayectoria.append(traj_pre)\n",
    "        verdadero.append(traj_tr)\n",
    "        #SE CALCULA LA METRICA ADE \n",
    "        diff = traj_pre[seq_length_obs:]-traj_tr[seq_length_obs:]\n",
    "        diff = diff**2\n",
    "        diff = np.sqrt(np.sum(diff,axis=1))\n",
    "        todo.append(diff)\n",
    "        \n",
    "        total_error += error_promedio(traj_pre , traj_tr, seq_length_obs)\n",
    "        total_final += error_desplazamiento_final(traj_pre, traj_tr)\n",
    "            \n",
    "    error_modelo = total_error/len(X)\n",
    "    error_fde_modelo = total_final/len(X)\n",
    "    \n",
    "    ade = [t for o in todo for t in o]\n",
    "    \n",
    "    print('---------Error--------')\n",
    "    print('ADE')\n",
    "    print(np.mean(ade))\n",
    "    \n",
    "    print('Error promedio')\n",
    "    print(error_modelo)\n",
    "    print('FDE')\n",
    "    print(error_fde_modelo)\n",
    "    return trayectoria, verdadero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_en_pixeles(cruce,8,4)\n",
    "p,v = sample_en_pixeles_cualitativamente(paralelos,8,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_names = [\"r\", \"g\", \"b\",\"c\",\"m\",\"y\", \"peachpuff\",\"grey\", \"fuchsia\",\"violet\",\n",
    "                   \"teal\",\"seagreen\",\"lime\",\"yellow\",\"coral\",\"aquamarine\",\"hotpink\"]\n",
    "\n",
    "\n",
    "plot(p[0][0:8,0],p[0][0:8,1],'*--',color= color_names[2],label = 'Observado')\n",
    "plot(p[0][7:,0],p[0][7:,1],'-',color=color_names[2],label='Predicho')\n",
    "plot(v[0][7:,0],v[0][7:,1],'--',color=color_names[4],label='GT')\n",
    "\n",
    "plot(p[1][0:8,0],p[1][0:8,1],'*--',color= color_names[2])\n",
    "plot(p[1][7:,0],p[1][7:,1],'-',color=color_names[2])\n",
    "plot(v[1][7:,0],v[1][7:,1],'--',color=color_names[4])\n",
    "\n",
    "#plt.show()\n",
    "plt.legend()\n",
    "plt.savefig(\"paralelos_absoluto.jpg\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
